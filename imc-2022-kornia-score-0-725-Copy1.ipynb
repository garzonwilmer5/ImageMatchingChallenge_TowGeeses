{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Welcome Back Kagglers \n\ncredit : https://www.kaggle.com/code/ammarali32/imc-2022-kornia-loftr-from-0-533-to-0-721","metadata":{"papermill":{"duration":0.014409,"end_time":"2022-04-22T17:27:27.894541","exception":false,"start_time":"2022-04-22T17:27:27.880132","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ***Import dependencies***","metadata":{"papermill":{"duration":0.017024,"end_time":"2022-04-22T17:28:29.85595","exception":false,"start_time":"2022-04-22T17:28:29.838926","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dry_run = False\n!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T22:51:48.318354Z","iopub.execute_input":"2022-05-09T22:51:48.318921Z","iopub.status.idle":"2022-05-09T22:52:48.210020Z","shell.execute_reply.started":"2022-05-09T22:51:48.318859Z","shell.execute_reply":"2022-05-09T22:52:48.208988Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport csv\nfrom glob import glob\nimport torch\nimport matplotlib.pyplot as plt\nimport kornia\nfrom kornia_moons.feature import *\nimport kornia as K\nimport kornia.feature as KF\nimport gc\nimport time\nimport typing\nimport copy\n#from pydegensac import  findFundamentalMatrix\n!cp ../input/super-glue-pretrained-network/models/superglue.py /opt/conda/lib/python3.7/site-packages/kornia/feature/loftr/utils/superglue.py \n\n\n","metadata":{"papermill":{"duration":2.469375,"end_time":"2022-04-22T17:28:32.342741","exception":false,"start_time":"2022-04-22T17:28:29.873366","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-09T22:52:48.212959Z","iopub.execute_input":"2022-05-09T22:52:48.213287Z","iopub.status.idle":"2022-05-09T22:52:51.211269Z","shell.execute_reply.started":"2022-05-09T22:52:48.213244Z","shell.execute_reply":"2022-05-09T22:52:51.210004Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# ***Model***","metadata":{"papermill":{"duration":0.01725,"end_time":"2022-04-22T17:28:32.378076","exception":false,"start_time":"2022-04-22T17:28:32.360826","status":"completed"},"tags":[]}},{"cell_type":"code","source":"matcher = KF.LoFTR(pretrained=None)\nmatcher.load_state_dict(torch.load(\"../input/kornia-loftr/loftr_outdoor.ckpt\")['state_dict'])\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmatcher = matcher.to(device).eval()","metadata":{"papermill":{"duration":4.74373,"end_time":"2022-04-22T17:28:37.138754","exception":false,"start_time":"2022-04-22T17:28:32.395024","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-09T22:52:51.213360Z","iopub.execute_input":"2022-05-09T22:52:51.213606Z","iopub.status.idle":"2022-05-09T22:52:53.004158Z","shell.execute_reply.started":"2022-05-09T22:52:51.213578Z","shell.execute_reply":"2022-05-09T22:52:53.003167Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## *Utils*","metadata":{"papermill":{"duration":0.016801,"end_time":"2022-04-22T17:28:37.172981","exception":false,"start_time":"2022-04-22T17:28:37.15618","status":"completed"},"tags":[]}},{"cell_type":"code","source":"src = '../input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]\n\n\ndef FlattenMatrix(M, num_digits=8):\n    '''Convenience function to write CSV files.'''\n    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\ndef cv2_Torch(img: np.ndarray, device:torch.device)->torch.Tensor:\n    img = K.image_to_tensor(img, False).float() /255.\n    img = img.to(device)\n    return K.color.rgb_to_grayscale(img)\n\n\ndef load_torch_image(fname:str, device:torch.device) -> (typing.Dict[str,torch.Tensor],float):\n    img = cv2.imread(fname)\n    scale = 840 / max(img.shape[0], img.shape[1]) \n    w = int(img.shape[1] * scale)\n    h = int(img.shape[0] * scale)\n    img = cv2.resize(img, (w, h))\n    \n    \n    img = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n    imgV = cv2.flip(img, 0)\n    imgH = cv2.flip(img, 1)\n    imgB = cv2.flip(imgV, 1)\n    images = {'base':img,\n             'vFlipped': imgV,\n             'hFlipped': imgH,\n             'bFlipped': imgB}   \n    images = {k: cv2_Torch(v,device) for k, v in images.items()}\n    \n    return images, scale\n                        \ndef reverseMirrorPoints(points:np.ndarray, length:typing.List[int], axis:typing.List[int]) -> np.ndarray:\n    for l,a in zip(length,axis):\n        points[:,a] = l - points[:,a] - 1 \n    return points\n                        \ndef getMatches(matcher:KF.LoFTR, input_dict:dict, th:float =0.4, foo = None,fooParams1:dict={},fooParams2:dict={}) -> (np.ndarray,np.ndarray):\n    with torch.no_grad():\n        correspondences = matcher(input_dict)\n    mkpts0 = correspondences['keypoints0'].cpu().numpy()\n    mkpts1 = correspondences['keypoints1'].cpu().numpy()\n    select = correspondences['confidence'].cpu().numpy() > th\n    if foo:\n        mkpts0 = foo(mkpts0[select,:],**fooParams1)\n        mkpts1 = foo(mkpts1[select,:],**fooParams2)\n    else:\n        mkpts0 = mkpts0[select,:]\n        mkpts1 = mkpts1[select,:]\n    return mkpts0, mkpts1","metadata":{"papermill":{"duration":0.035034,"end_time":"2022-04-22T17:28:37.22538","exception":false,"start_time":"2022-04-22T17:28:37.190346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-09T22:57:38.630986Z","iopub.execute_input":"2022-05-09T22:57:38.631943Z","iopub.status.idle":"2022-05-09T22:57:38.657646Z","shell.execute_reply.started":"2022-05-09T22:57:38.631883Z","shell.execute_reply":"2022-05-09T22:57:38.656564Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# ***Inference***","metadata":{"papermill":{"duration":0.016772,"end_time":"2022-04-22T17:28:37.259611","exception":false,"start_time":"2022-04-22T17:28:37.242839","status":"completed"},"tags":[]}},{"cell_type":"code","source":"F_dict = {}\n\nfor i, row in enumerate(test_samples):\n    print(i)\n    sample_id, batch_id, image_1_id, image_2_id = row\n    # Load the images.\n    st = time.time()\n    images1, scale1 =load_torch_image(f'{src}/test_images/{batch_id}/{image_1_id}.png', device)\n    images2, scale2 =load_torch_image(f'{src}/test_images/{batch_id}/{image_1_id}.png', device)\n    \n    input_dict = {key:{\"image0\": images1[key],\"image1\": images2[key]} for key in images1.keys()}\n    w1:int = images1['base'].shape[-1]\n    h1:int = images1['base'].shape[-2]\n    w2:int = images2['base'].shape[-1]\n    h2:int = images2['base'].shape[-2]\n    \n    reverseFoo = {'base': {'foo': None},\n                  'vFlipped': {'foo': reverseMirrorPoints,\n                               'fooParams1': {'length':[h1],'axis':[1]},\n                               'fooParams2': {'length':[h2],'axis':[1]}},\n                  'hFlipped': {'foo': reverseMirrorPoints,\n                               'fooParams1': {'length':[w1],'axis':[0]},\n                               'fooParams2': {'length':[w2],'axis':[0]}},\n                  'bFlipped': {'foo': reverseMirrorPoints,\n                               'fooParams1': {'length':[w1,h1],'axis':[0,1]},\n                               'fooParams2': {'length':[w2,h2],'axis':[0,1]}}} \n    mkpts = [getMatches(matcher, v,**reverseFoo[k]) for k,v in input_dict.items()]\n    \n    mkpts0 = np.empty((0,2))\n    mkpts1 = np.empty((0,2))\n    for points in mkpts:\n        mkpts0 = np.concatenate((mkpts0, points[0]), axis=0)\n        mkpts1 = np.concatenate((mkpts1, points[1]), axis=0)\n    mkpts0 /= scale1\n    mkpts1 /= scale2\n    \n    if len(mkpts0) > 7:\n        F, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.1823, 0.999999, 220000)\n        #F, mask = findFundamentalMatrix(mkpts0, mkpts1, 3.0)\n        assert F.shape == (3, 3), 'Malformed F?'\n        F_dict[sample_id] = F\n    else:\n        F_dict[sample_id] = np.zeros((3, 3))\n        continue\n    gc.collect()\n    nd = time.time()    \n    if (i < 3):\n        print(\"Running time: \", nd - st, \" s\")\n\nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in F_dict.items():\n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"papermill":{"duration":18.780795,"end_time":"2022-04-22T17:28:56.057457","exception":false,"start_time":"2022-04-22T17:28:37.276662","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-09T22:58:05.916285Z","iopub.execute_input":"2022-05-09T22:58:05.916562Z","iopub.status.idle":"2022-05-09T23:01:47.791986Z","shell.execute_reply.started":"2022-05-09T22:58:05.916530Z","shell.execute_reply":"2022-05-09T23:01:47.790966Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"dry_run = False\n!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl<center>\n    <h2 style=\"color: #022047\"> Thanks for reading ðŸ¤—  </h2>\n</center>","metadata":{"papermill":{"duration":0.067194,"end_time":"2022-04-22T17:28:56.193515","exception":false,"start_time":"2022-04-22T17:28:56.126321","status":"completed"},"tags":[]}}]}